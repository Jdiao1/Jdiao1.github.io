## Learning to use Confusion Matrix for CNN models nad TSne

 a confusion matrix effectly represents classes the model predicts correctly and which classes the model predicts incorrectly.
 
 
 ![image of mat](images/confusmatrix.png)
 
Below is an example found to simply implement the confusion matrix:
https://leslietj.github.io/2020/06/22/Draw-Confusion-Matrix-for-CNN-models/


# T-sne ->  t-Distributed Stochastic Neighbor Embedding

 
 Use case:
 Dimensionality reduction technique used for visualizing high-dimensional data in a lower-dimensional space. 
 It is particularly effective in visualizing complex and non-linear relationships within the data.

Some properties and definitions on t-sne method for dimensionality reduction based on PCA.

**Constructing Probability Distributions**: 
From the pairwise similarities, t-SNE constructs probability distributions for each data point. 
These distributions represent the likelihood of choosing a neighboring point as a neighbor, both locally and globally. 
The probability distribution is defined for both the high-dimensional space and the low-dimensional space.

**Mapping to Lower-Dimensional Space**: 
t-SNE aims to find a lower-dimensional representation where the pairwise similarities are preserved. 
It achieves this by minimizing the Kullback-Leibler (KL) divergence between the probability distributions in the high-dimensional and low-dimensional spaces. 
The KL divergence measures the difference between two probability distributions.

**Gradient Descent Optimization**: 
t-SNE uses gradient descent optimization to minimize the KL divergence. 
It iteratively updates the positions of the data points in the low-dimensional space to minimize the discrepancy between the high-dimensional and low-dimensional probability distributions. 
The optimization process involves adjusting the learning rate, momentum, and other hyperparameters to find an optimal mapping.
